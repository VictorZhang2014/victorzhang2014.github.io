<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <meta name="google-site-verification" content="" />
  
  <title>Classifying Images with Vision and Core ML</title>
  <meta name="author" content="Victor Zhang">
  <meta name="description" content="iOS,é€†å‘å·¥ç¨‹,AI,.NET">
  
  
  <meta property="og:title" content="Classifying Images with Vision and Core ML"/>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:site_name" content="Simple, but perfect"/>
  <link href="/apple-touch-icon-precomposed.png" sizes="180x180" rel="apple-touch-icon-precomposed">
  <link rel="alternate" href="/atom.xml" title="Simple, but perfect" type="application/atom+xml">
  <link rel="stylesheet" href="//cdn.bootcss.com/bootstrap/3.3.6/css/bootstrap.min.css">
  <link rel="stylesheet" href="/css/m.min.css">
  <link rel="icon" type="image/x-icon" href="/favicon.ico">
</head>

<body>
  <a id="top"></a>
  <div id="main">
    <div class="behind">
      <a href="/" class="back black-color">
        <svg class="i-close" viewBox="0 0 32 32" width="22" height="22" fill="none" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="3">
            <path d="M2 30 L30 2 M30 30 L2 2"></path>
        </svg>
      </a>
      <div class="description">
        &nbsp;What will you do if you weren't afraid ? 
      </div>
    </div>
    <div class="container">
      

  <article class="standard post">
    <div class="title">
      
  
    <h1 class="page-title center">
        Classifying Images with Vision and Core ML
    </h1>
  


    </div>
    <div class="meta center">
      
<time datetime="2017-10-23T08:45:58.000Z">
<svg class="i-calendar" viewBox="0 0 32 32" width="14" height="14" fill="none" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2">
    <path d="M2 6 L2 30 30 30 30 6 Z M2 15 L30 15 M7 3 L7 9 M13 3 L13 9 M19 3 L19 9 M25 3 L25 9"></path>
  </svg>
  &nbsp;
  2017-10-23
</time>



    
    &nbsp;
    <svg class="i-tag" viewBox="0 0 32 32" width="14" height="14" fill="none" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2">
      <circle cx="24" cy="8" r="2"></circle>
      <path d="M2 18 L18 2 30 2 30 14 14 30 Z"></path>
    </svg>
    &nbsp;
    <a href="/categories/AI/">AI</a>




    
    &nbsp;
    <svg class="i-tag" viewBox="0 0 32 32" width="14" height="14" fill="none" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2">
      <circle cx="24" cy="8" r="2"></circle>
      <path d="M2 18 L18 2 30 2 30 14 14 30 Z"></path>
    </svg>
    &nbsp;
    <a href="/tags/Core-ML-Classifying-Images/">Core ML, Classifying Images</a>


    </div>
    <hr>
    <div class="picture-container">
      
    </div>
    <p>If you donâ€™t know the basic use of Core ML, see <a href="/2017/10/23/Getting-Started-on-CoreML-by-Three-Steps/">this page</a> , on the contrary, keep going our tutorial.</p>
<p>Use Vision with Core ML to perform image classification.</p>
<h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>With the <code>Core ML</code> framework, you can use a trained machine learning model to classify input data. The Vision framework works with Core ML to apply classification models to images, and to preprocess those images to make machine learning tasks easier and more reliable.</p>
<p>This tutorial Iâ€™m going to show you the open source <code>MobileNet</code> model, which identifies an image using 1000 classification categories as seen in the example screenshots below.</p>
<p><img src="/img/AI/officialClassifyImages.png" alt="Official Classifying Image"></p>
<center>Figure - Official Test Case <a href="https://docs-assets.developer.apple.com/published/43bca2cbbd/ClassifyingImageswithVisionandCoreML.zip" target="_blank" rel="noopener">Download Sample Code</a></center>

<p><br><br><img src="/img/AI/FountainMobileNet.jpeg" alt="" width="320" height="568"><img src="/img/AI/StrawberryMobileNet.jpeg" alt="" width="320" height="568"><br><img src="/img/AI/LuHanMobileNet.jpeg" alt="" width="320" height="568"><img src="/img/AI/avatarMobileNet.jpeg" alt="" width="320" height="568"></p>
<center>Figure - My Test Case</center>

<p>Now, weâ€™ve seen itâ€™s completely identified in official test case, but in my test case, half of them are failed to be identified. So I can sum this example code up,the trained model is unmatured. </p>
<p>But anyway, this is a good and easy step for us to going.</p>
<h2 id="Start-to-my-performance"><a href="#Start-to-my-performance" class="headerlink" title="Start to my performance"></a>Start to my performance</h2><p><code>Core ML</code> automatically generates a Swift class which is <code>MobileNet</code>, that provides easy access to your ML model. To set up a Vision request using the model, create an instance of that class and use its model property to create a <code>VNCoreMLRequest</code> object. Use the request objectâ€™s completion handler to specify a method to receive results from the model after you run the request. </p>
<p><strong> Download the Model </strong><br><a href="https://docs-assets.developer.apple.com/coreml/models/MobileNet.mlmodel" target="_blank" rel="noopener">Download Model</a><br>After downloaded, dragging it to your project, complete snippet code as seen below.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line">import UIKit</span><br><span class="line">import CoreML</span><br><span class="line">import Vision</span><br><span class="line"></span><br><span class="line">class ViewController: UIViewController &#123;</span><br><span class="line">    </span><br><span class="line">    override func touchesBegan(_ touches: Set&lt;UITouch&gt;, with event: UIEvent?) &#123;</span><br><span class="line">        choosePhotosAndHandle()</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    //1. Choose an image and handle it</span><br><span class="line">    func choosePhotosAndHandle() &#123;</span><br><span class="line">        //Specific an image</span><br><span class="line">        let imgpath = Bundle.main.path(forResource: &quot;Strawberry&quot;, ofType: &quot;.jpeg&quot;)</span><br><span class="line">        if imgpath == nil &#123;</span><br><span class="line">            print(&quot;You specified image is nonexistent&quot;)</span><br><span class="line">            return</span><br><span class="line">        &#125;</span><br><span class="line">        let image = UIImage(contentsOfFile: imgpath!)!</span><br><span class="line">        let orientation = CGImagePropertyOrientation(rawValue: UInt32(image.imageOrientation.rawValue))!</span><br><span class="line">        guard let ciImage = CIImage(image: image) else &#123;</span><br><span class="line">            fatalError(&quot;Unable to create \(CIImage.self) from \(image).&quot;)</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        DispatchQueue.global(qos: .userInitiated).async &#123;</span><br><span class="line">            let handler = VNImageRequestHandler(ciImage: ciImage, orientation: orientation)</span><br><span class="line">            do &#123;</span><br><span class="line">                try handler.perform([self.classifyRequest])</span><br><span class="line">            &#125; catch &#123;</span><br><span class="line">                print(&quot;Failed to perform classification.\n\(error.localizedDescription)&quot;)</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    //2.Initialized an instance of MobileNet in lazy mode</span><br><span class="line">    lazy var classifyRequest: VNCoreMLRequest = &#123;</span><br><span class="line">        let mlModel = MobileNet().model</span><br><span class="line">        </span><br><span class="line">        do &#123;</span><br><span class="line">            let model = try VNCoreMLModel(for: mlModel)</span><br><span class="line">            let request = VNCoreMLRequest(model: model) &#123; [weak self] request, error in</span><br><span class="line">                self?.processClassifications(for: request, error: error)</span><br><span class="line">            &#125;</span><br><span class="line">            request.imageCropAndScaleOption = .centerCrop</span><br><span class="line">            return request</span><br><span class="line">        &#125; catch &#123;</span><br><span class="line">            fatalError(&quot;Failed to load Vision ML model: \(error)&quot;)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;()</span><br><span class="line">    </span><br><span class="line">    // 3.This is an callback</span><br><span class="line">    func processClassifications(for request: VNRequest, error: Error?) &#123;</span><br><span class="line">        DispatchQueue.main.async &#123;</span><br><span class="line">            guard let results = request.results else &#123;</span><br><span class="line">                print(&quot;Unable to classify image. \(error!.localizedDescription)&quot;)</span><br><span class="line">                return</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            // The `results` will always be `VNClassificationObservation`s, as specified by the Core ML model in this project.</span><br><span class="line">            let classifications = results as! [VNClassificationObservation]</span><br><span class="line">            </span><br><span class="line">            if classifications.isEmpty &#123;</span><br><span class="line">                print(&quot;Nothing recognized&quot;)</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                // Display top classifications ranked by confidence in the UI</span><br><span class="line">                let topClassifications = classifications.prefix(2)</span><br><span class="line">                let descriptions = topClassifications.map(&#123; classification in</span><br><span class="line">                    return String(format: &quot;   (%.2f) %@&quot;, classification.confidence, classification.identifier)</span><br><span class="line">                &#125;)</span><br><span class="line">                </span><br><span class="line">                //This is the output result</span><br><span class="line">                print(&quot;Classification: \n&quot; + descriptions.joined(separator: &quot;\n&quot;))</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>What we will always be seen in the console window as shown below:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Classification: </span><br><span class="line">   (1.00) strawberry</span><br><span class="line">   (0.00) trifle</span><br></pre></td></tr></table></figure></p>
<p>The property of <code>imageCropAndScaleOption</code> in the class of <code>VNCoreMLRequest</code> illustration is an ML model processes input images in a fixed aspect ratio, but input images may have arbitrary aspect ratio, so Vision must scale of crop the image to fit. For best results, set a value to this property that matches the image layout the model was trained with. For the <a href="https://developer.apple.com/machine-learning/" target="_blank" rel="noopener">available classification models</a>, the <code>centerCrop</code> option is appropriate unless noted otherwise.</p>
<p><a href="https://developer.apple.com/documentation/vision/classifying_images_with_vision_and_core_ml" target="_blank" rel="noopener">Official Classifying Images Tutorial</a><br><br><br><br></p>
<p>=======================================================================================================<br>å¦‚æœä½ è¿˜ä¸çŸ¥é“Core MLçš„åŸºæœ¬ä½¿ç”¨ï¼Œé‚£å°±å…ˆçœ‹çœ‹è¿™ä¸ª<a href="/2017/10/23/Getting-Started-on-CoreML-by-Three-Steps/">æ•™ç¨‹</a> ï¼Œç›¸åï¼Œå°±ç›´æ¥å¾€ä¸‹çœ‹å§ã€‚</p>
<p>ä½¿ç”¨<code>Vision with Core ML</code>æ¥æ‰§è¡Œå›¾ç‰‡åˆ†ç±»ï¼ˆ<code>image classification</code>ï¼‰ã€‚</p>
<h2 id="æ¦‚è¿°"><a href="#æ¦‚è¿°" class="headerlink" title="æ¦‚è¿°"></a>æ¦‚è¿°</h2><p>é€šè¿‡<code>Core ML</code>frameworkï¼Œä½ å¯ä»¥é€šè¿‡å·²ç»è®­ç»ƒçš„æœºå™¨æ¨¡å‹å¯¹è¾“å…¥çš„æ•°æ®ï¼ˆæä¾›çš„å›¾ç‰‡ï¼‰è¿›è¡Œåˆ†ç±»ã€‚<code>Vision</code>frameworkä¸<code>Core ML</code>ç´§å¯†ç»“åˆå·¥ä½œï¼Œåº”ç”¨äºåˆ†ç±»æ¨¡å‹åˆ°å›¾ç‰‡ï¼Œå¹¶ä¸”é¢„å¤„ç†é‚£äº›å›¾ç‰‡ï¼Œä½¿æœºå™¨å­¦ä¹ ä»»åŠ¡æ›´ç®€å•ï¼Œæ›´å¯é ã€‚</p>
<p>æœ¬ç« æ•™ç¨‹ï¼Œæˆ‘å°†å±•ç¤ºç»™ä½ ä¸€ä¸ªå¼€æº<code>MobileNet</code>æ¨¡å‹çš„ä½¿ç”¨ï¼Œè¿™ä¸ªæ¨¡å‹èƒ½ä½¿ç”¨1000ä¸­åˆ†ç±»ç±»å‹æ¥è¯†åˆ«å›¾ç‰‡ï¼Œå¦‚ä¸‹æˆªå›¾æ‰€ç¤ºï¼š</p>
<p><img src="/img/AI/officialClassifyImages.png" alt="å®˜æ–¹åˆ†ç±»åå›¾ç‰‡æ•ˆæœ"></p>
<center>å›¾ç‰‡ - å®˜æ–¹æµ‹è¯•æ¡ˆä¾‹ <a href="https://docs-assets.developer.apple.com/published/43bca2cbbd/ClassifyingImageswithVisionandCoreML.zip" target="_blank" rel="noopener">ä¸‹è½½æ ·æœ¬ä»£ç </a></center>

<p><br><br><img src="/img/AI/FountainMobileNet.jpeg" alt="" width="320" height="568"><img src="/img/AI/StrawberryMobileNet.jpeg" alt="" width="320" height="568"><br><img src="/img/AI/LuHanMobileNet.jpeg" alt="" width="320" height="568"><img src="/img/AI/avatarMobileNet.jpeg" alt="" width="320" height="568"></p>
<center>å›¾ç‰‡ - æˆ‘çš„æµ‹è¯•æ¡ˆä¾‹</center>

<p>ç°åœ¨ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œå®˜æ–¹çš„æµ‹è¯•æ¡ˆä¾‹çš„å›¾ç‰‡å…¨éƒ¨æ­£ç¡®è¯†åˆ«äº†ï¼Œä½†æ˜¯åœ¨æˆ‘çš„æ¡ˆä¾‹é‡Œï¼Œä¸€åŠè¢«è¯†åˆ«å‡ºæ¥äº†ï¼Œä¸€åŠå¤±è´¥äº†ã€‚ç®€å•çš„æ€»ç»“ï¼Œè¿™ä¸ªæ¨¡å‹å¹¶ä¸æˆç†Ÿã€‚</p>
<p>ä½†æ˜¯ï¼Œä¸ç®¡æ€ä¹ˆæ ·ï¼Œè¿™å¯¹æˆ‘ä»¬æ¥è¯´ï¼Œæ˜¯ä¸€ä¸ªç®€å•è€Œä¸”å¾ˆä¸é”™çš„å¼€å§‹ã€‚</p>
<h2 id="å¼€å§‹æˆ‘çš„è¡¨æ¼”å§ğŸ˜„"><a href="#å¼€å§‹æˆ‘çš„è¡¨æ¼”å§ğŸ˜„" class="headerlink" title="å¼€å§‹æˆ‘çš„è¡¨æ¼”å§ğŸ˜„"></a>å¼€å§‹æˆ‘çš„è¡¨æ¼”å§ğŸ˜„</h2><p><code>Core ML</code>è‡ªåŠ¨ç”Ÿæˆ<code>Swift</code>ç±»ï¼Œè¿™ä¸ªç±»å«åš<code>MobileNet</code>ï¼Œæä¾›äº†è½»æ¾çš„è®¿é—®è¿™ä¸ªMLæ¨¡å‹ã€‚ä½¿ç”¨è¿™ä¸ªæ¨¡å‹æ¥åˆ›å»º<code>VNCoreMLRequest</code>å¯¹è±¡ï¼Œå¹¶ä¸”è®¾ç½®ç›¸å…³çš„å±æ€§ï¼Œæœ€åç»™è¿™ä¸ªè¯·æ±‚æŒ‡å®šä¸€ä¸ªå›è°ƒç”¨æ¥æ¥æ”¶æ¨¡å‹çš„è¾“å‡ºç»“æœã€‚</p>
<p><a href="https://docs-assets.developer.apple.com/coreml/models/MobileNet.mlmodel" target="_blank" rel="noopener">ä¸‹è½½æ¨¡å‹</a><br>ä¸‹è½½åï¼ŒæŠŠè¿™ä¸ªæ¨¡å‹æ‹–æ‹½åˆ°ä½ çš„é¡¹ç›®ï¼Œå®Œæ•´çš„ä»£ç å¦‚ä¸‹æ˜¾ç¤º</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line">import UIKit</span><br><span class="line">import CoreML</span><br><span class="line">import Vision</span><br><span class="line"></span><br><span class="line">class ViewController: UIViewController &#123;</span><br><span class="line">    </span><br><span class="line">    override func touchesBegan(_ touches: Set&lt;UITouch&gt;, with event: UIEvent?) &#123;</span><br><span class="line">        choosePhotosAndHandle()</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    //1. é€‰æ‹©ä¸€å¼ å›¾ç‰‡å¹¶ä¸”å¤„ç†å®ƒ</span><br><span class="line">    func choosePhotosAndHandle() &#123;</span><br><span class="line">        //æŒ‡å®šä¸€å¼ å›¾ç‰‡</span><br><span class="line">        let imgpath = Bundle.main.path(forResource: &quot;Strawberry&quot;, ofType: &quot;.jpeg&quot;)</span><br><span class="line">        if imgpath == nil &#123;</span><br><span class="line">            print(&quot;You specified image is nonexistent&quot;)</span><br><span class="line">            return</span><br><span class="line">        &#125;</span><br><span class="line">        let image = UIImage(contentsOfFile: imgpath!)!</span><br><span class="line">        let orientation = CGImagePropertyOrientation(rawValue: UInt32(image.imageOrientation.rawValue))!</span><br><span class="line">        guard let ciImage = CIImage(image: image) else &#123;</span><br><span class="line">            fatalError(&quot;Unable to create \(CIImage.self) from \(image).&quot;)</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        DispatchQueue.global(qos: .userInitiated).async &#123;</span><br><span class="line">            let handler = VNImageRequestHandler(ciImage: ciImage, orientation: orientation)</span><br><span class="line">            do &#123;</span><br><span class="line">                try handler.perform([self.classifyRequest])</span><br><span class="line">            &#125; catch &#123;</span><br><span class="line">                print(&quot;æœªèƒ½æ‰§è¡Œåˆ†ç±».\n\(error.localizedDescription)&quot;)</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    //2.æ‡’åŠ è½½MobileNet</span><br><span class="line">    lazy var classifyRequest: VNCoreMLRequest = &#123;</span><br><span class="line">        let mlModel = MobileNet().model</span><br><span class="line">        </span><br><span class="line">        do &#123;</span><br><span class="line">            let model = try VNCoreMLModel(for: mlModel)</span><br><span class="line">            let request = VNCoreMLRequest(model: model) &#123; [weak self] request, error in</span><br><span class="line">                self?.processClassifications(for: request, error: error)</span><br><span class="line">            &#125;</span><br><span class="line">            request.imageCropAndScaleOption = .centerCrop</span><br><span class="line">            return request</span><br><span class="line">        &#125; catch &#123;</span><br><span class="line">            fatalError(&quot;Failed to load Vision ML model: \(error)&quot;)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;()</span><br><span class="line">    </span><br><span class="line">    // 3.è¿™æ˜¯å›è°ƒ</span><br><span class="line">    func processClassifications(for request: VNRequest, error: Error?) &#123;</span><br><span class="line">        DispatchQueue.main.async &#123;</span><br><span class="line">            guard let results = request.results else &#123;</span><br><span class="line">                print(&quot;Unable to classify image. \(error!.localizedDescription)&quot;)</span><br><span class="line">                return</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            // `results`æ°¸è¿œéƒ½æ˜¯`VNClassificationObservation`æ•°ç»„ï¼Œåœ¨è¿™ä¸ªé¡¹ç›®ä¸­æœ‰ML Modelç‰¹æŒ‡çš„</span><br><span class="line">            let classifications = results as! [VNClassificationObservation]</span><br><span class="line">            </span><br><span class="line">            if classifications.isEmpty &#123;</span><br><span class="line">                print(&quot;Nothing recognized&quot;)</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                // Display top classifications ranked by confidence in the UI</span><br><span class="line">                let topClassifications = classifications.prefix(2)</span><br><span class="line">                let descriptions = topClassifications.map(&#123; classification in</span><br><span class="line">                    return String(format: &quot;   (%.2f) %@&quot;, classification.confidence, classification.identifier)</span><br><span class="line">                &#125;)</span><br><span class="line">                </span><br><span class="line">                //è¿™æ˜¯è¾“å‡ºç»“æœ</span><br><span class="line">                print(&quot;Classification: \n&quot; + descriptions.joined(separator: &quot;\n&quot;))</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>æˆ‘ä»¬å¯ä»¥åœ¨æ§åˆ¶å°çª—å£çœ‹åˆ°å¦‚ä¸‹è¾“å‡ºï¼š<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Classification: </span><br><span class="line">   (1.00) strawberry</span><br><span class="line">   (0.00) trifle</span><br></pre></td></tr></table></figure></p>
<p>åœ¨ç±»<code>VNCoreMLRequest</code>çš„å±æ€§<code>imageCropAndScaleOption</code>ï¼Œè§£é‡Šï¼šä¸€ä¸ªMLæ¨¡å‹å¤„ç†å›¾ç‰‡æ—¶æ˜¯åŸºäºå›ºå®šå®½é«˜æ¯”ï¼ˆfixed aspect ratioï¼‰çš„ï¼Œä½†æ˜¯æä¾›çš„å›¾ç‰‡çš„å®½é«˜æ¯”å¯èƒ½æ˜¯ä»»æ„çš„ï¼Œæ‰€ä»¥<code>Vision</code>å°±å¿…é¡»æŠŠå›¾ç‰‡è¿›è¡Œè£åˆ‡æˆ–è€…è§„æ ¼åŒ–åå»é€‚é…è¿™ä¸ªæ¨¡å‹æ‰€éœ€ã€‚ä¸ºäº†è¾¾åˆ°æœ€å¥½çš„æ•ˆæœï¼Œæˆ‘ä»¬ä¸€èˆ¬ä¼šè®¾ç½®ä¸€ä¸ªå€¼æ¥åŒ¹é…å›¾ç‰‡çš„å¸ƒå±€ï¼Œè¿™æ ·çš„å›¾ç‰‡çš„å¸ƒå±€å°±æ˜¯æ¨¡å‹æ‰€éœ€è¦çš„ã€‚<a href="https://developer.apple.com/machine-learning/" target="_blank" rel="noopener">æ‰€æœ‰å¯ç”¨çš„åˆ†ç±»æ¨¡å‹</a>ï¼Œå‚æ•°é€‰é¡¹<code>centerCrop</code>æ˜¯è¾ƒä¸ºåˆé€‚çš„ï¼Œé™¤éæœ‰ç‰¹æ®Šè¯´æ˜ç”¨åˆ«çš„ï¼Œå¦åˆ™ï¼Œå°±æ˜¯è¿™ä¸ªã€‚</p>
<p><a href="https://developer.apple.com/documentation/vision/classifying_images_with_vision_and_core_ml" target="_blank" rel="noopener">å®˜æ–¹å›¾ç‰‡åˆ†ç±»æ•™ç¨‹</a></p>


  </article>
  </script>
    <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
  </script>
  <div class="busuanzi center">
    page PV:&nbsp;<span id="busuanzi_value_page_pv"></span>&nbsp;ãƒ»&nbsp;
    site PV:&nbsp;<span id="busuanzi_value_site_pv"></span>&nbsp;ãƒ»&nbsp;
    site UV:&nbsp;<span id="busuanzi_value_site_uv"></span>
  </div>




    </div>
  </div>
  <footer class="page-footer"><div class="clearfix">
</div>
<div class="right-foot container">
    <div class="firstrow">
        <a href="#top" target="_self">
        <svg class="i-caret-right" viewBox="0 0 32 32" width="24" height="24" fill="none" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="3">
            <path d="M10 30 L26 16 10 2 Z"></path>
        </svg>
        </a>
        Â© Victor Zhang 2014-2018
    </div>
    <div class="secondrow">
        <a href="https://github.com/gaoryrt/hexo-theme-pln">
        Theme Pln
        </a>
    </div>
</div>
<div class="clearfix">
</div>
</footer>
  <script src="//cdn.bootcss.com/jquery/2.2.1/jquery.min.js"></script>
<script src="/js/search.min.js"></script>
<script type="text/javascript">

// disqus scripts


// dropdown scripts
$(".dropdown").click(function(event) {
  var current = $(this);
  event.stopPropagation();
  $(current).children(".dropdown-content")[($(current).children(".dropdown-content").hasClass("open"))?'removeClass':'addClass']("open")
});
$(document).click(function(){
    $(".dropdown-content").removeClass("open");
})

var path = "/search.xml";
searchFunc(path, 'local-search-input', 'local-search-result');

</script>

</body>
</html>
